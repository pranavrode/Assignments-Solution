{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b854858",
   "metadata": {},
   "source": [
    "#  ASSIGNMENT - 19(KMeans Clustering)\n",
    "## Solution/Ans  by - Pranav Rode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc4ef8c",
   "metadata": {},
   "source": [
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811724a3",
   "metadata": {},
   "source": [
    "## 1. What is Unsupervised Machine Learning?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d2dd79",
   "metadata": {},
   "source": [
    "Unsupervised machine learning is a type of machine learning where the model is trained on unlabeled data, <br>\n",
    "meaning that the algorithm is not provided with explicit guidance or labeled outcomes. <br>\n",
    "In unsupervised learning, the system tries to identify patterns and relationships within the <br>\n",
    "data without any predefined categories or target variables.\n",
    "\n",
    "The main goal of unsupervised learning is to explore the inherent structure within the data, <br>\n",
    "discover hidden patterns, and gain insights into the underlying relationships. <br>\n",
    "Clustering and dimensionality reduction are common techniques used in unsupervised learning.\n",
    "\n",
    "Two prominent methods in unsupervised learning are:\n",
    "\n",
    "1. **Clustering:** This involves grouping similar data points together based on certain <br>\n",
    "features or characteristics. K-Means clustering, hierarchical clustering, and DBSCAN are <br>\n",
    "examples of clustering algorithms.\n",
    "\n",
    "2. **Dimensionality Reduction:** This technique aims to reduce the number of features or <br>\n",
    "variables in the dataset while preserving its essential information. <br>\n",
    "Principal Component Analysis (PCA) and t-Distributed Stochastic Neighbor Embedding (t-SNE) <br>\n",
    "are popular dimensionality reduction methods.\n",
    "\n",
    "In summary, unsupervised learning is about extracting meaningful insights from data without <br>\n",
    "predefined labels, making it a valuable tool for pattern recognition, data exploration, and <br>\n",
    "discovering hidden structures within datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3090bec",
   "metadata": {},
   "source": [
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca60e08",
   "metadata": {},
   "source": [
    "## 2. Explain the steps of the k-Means Clustering Algorithm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec2e84b",
   "metadata": {},
   "source": [
    "**Example:**\n",
    "Suppose we have the following data points in a 2-dimensional space:\n",
    "\n",
    "$ Data\\ Points = \\{(2, 3), (5, 7), (8, 3), (6, 4), (2, 8), (7, 6), (6, 2)\\} $\n",
    "\n",
    "**Step 1: Initialization**\n",
    "- Choose the number of clusters (\\(k\\)) - Let's say \\(k = 2\\).\n",
    "- Randomly initialize centroids for each cluster. For simplicity, let's choose the first <br>\n",
    "    two data points as initial centroids:\n",
    "  - $ Centroid_1 = (2, 3) $\n",
    "  - $ Centroid_2 = (5, 7) $\n",
    "\n",
    "**Step 2: Assign Data Points to Clusters**\n",
    "- Calculate the Euclidean distance between each data point and both centroids.\n",
    "- Assign each point to the cluster with the nearest centroid.\n",
    "\n",
    "$ \\ Cluster_1: \\{(2, 3), (2, 8), (6, 2)\\} $\n",
    "\n",
    "$ \\ Cluster_2: \\{(5, 7), (8, 3), (6, 4), (7, 6)\\} $\n",
    "\n",
    "**Step 3: Update Centroids**\n",
    "- Recalculate the centroids based on the mean of data points in each cluster.\n",
    "\n",
    "$ Centroid_1 = \\left(\\frac{2+2+6}{3}, \\frac{3+8+2}{3}\\right) = (3.33, 4.33) $\n",
    "\n",
    "$ Centroid_2 = \\left(\\frac{5+8+6+7}{4}, \\frac{7+3+4+6}{4}\\right) = (6.5, 5) $\n",
    "\n",
    "**Step 4: Repeat**\n",
    "- Repeat steps 2 and 3 until convergence.\n",
    "\n",
    "**Iteration 2:**\n",
    "  - Reassign data points to clusters based on new centroids.\n",
    "  - Update centroids.\n",
    "\n",
    "**Iteration 3:**\n",
    "  - Repeat the process.\n",
    "\n",
    "Continue iterations until the centroids stabilize. The final clusters and centroids will <br>\n",
    "represent the k-Means clustering solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd03c75e",
   "metadata": {},
   "source": [
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f62aad8",
   "metadata": {},
   "source": [
    "## 3. What is K in K-means algorithm and <br> what is its significance?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7630f1",
   "metadata": {},
   "source": [
    "In the k-Means algorithm, the \"K\" represents the number of clusters that the algorithm aims to <br>\n",
    "identify in a given dataset. It is a user-defined parameter, and choosing the right value for K is <br>\n",
    "a crucial step in the clustering process.\n",
    "\n",
    "The significance of K lies in determining the number of centroids (cluster centers) the algorithm <br>\n",
    "should create to group the data points effectively. Each centroid represents the center of a cluster,<br>\n",
    "and the data points are assigned to the nearest centroid.\n",
    "\n",
    "Selecting an appropriate value for K depends on the underlying structure of the data and the <br>\n",
    "objectives of the analysis. <br>\n",
    "Here are a few considerations regarding the significance of K:\n",
    "\n",
    "1. **Impact on Cluster Interpretability:**\n",
    "   - Smaller values of K tend to create larger, more generalized clusters.\n",
    "   - Larger values of K result in smaller, more specific clusters.\n",
    "\n",
    "2. **Application Context:**\n",
    "   - The choice of K should align with the problem you are solving. <br>\n",
    "   For example, in customer segmentation, K might represent the number of distinct customer groups.\n",
    "\n",
    "3. **Elbow Method:**\n",
    "   - One common method for choosing K is the \"Elbow Method.\" It involves running the k-Means <br>\n",
    "   algorithm for a range of K values and plotting the sum of squared distances from each point <br>\n",
    "   to its assigned centroid (inertia or distortion). The point where the reduction in distortion <br>\n",
    "   begins to slow down (forming an elbow-like shape in the plot) is often a good choice for K.\n",
    "\n",
    "4. **Silhouette Score:**\n",
    "   - Another method is the silhouette score, which measures how similar an object is to its <br>\n",
    "   cluster compared to other clusters. A higher silhouette score indicates better-defined clusters.\n",
    "\n",
    "5. **Domain Knowledge:**\n",
    "   - In some cases, domain knowledge or business requirements may guide the choice of K. <br>\n",
    "   For example, if you know there are three distinct market segments for a product, <br>\n",
    "   K=3 may be a reasonable choice.\n",
    "\n",
    "Choosing an optimal K is often an iterative process, and the performance of the clustering <br>\n",
    "algorithm should be assessed using various metrics. Experimenting with different values of K <br>\n",
    "and assessing the quality of resulting clusters helps in finding the most meaningful and <br>\n",
    "interpretable partitioning of the data.\n",
    "\n",
    "In summary, K in the k-Means algorithm represents the number of clusters, and its significance <br>\n",
    "lies in determining the granularity and interpretability of the identified clusters. <br>\n",
    "Selecting an appropriate K is a critical aspect of successfully applying the k-Means <br>\n",
    "algorithm to a specific dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbfeb8f",
   "metadata": {},
   "source": [
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c493fd0f",
   "metadata": {},
   "source": [
    "## 4. What is the difference between the Manhattan <br> Distance and Euclidean Distance in Clustering?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2b8145",
   "metadata": {},
   "source": [
    "Formulas for both Manhattan Distance and Euclidean Distance:\n",
    "\n",
    "- **Manhattan Distance:**\n",
    "  $ \\text{Manhattan Distance} = |x_1 - y_1| + |x_2 - y_2| $\n",
    "<br>\n",
    "\n",
    "- **Euclidean Distance:**\n",
    "  $ \\text{Euclidean Distance} = \\sqrt{(x_1 - y_1)^2 + (x_2 - y_2)^2} $\n",
    "\n",
    "These formulas explicitly show the calculation of distances between points in a two-dimensional space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409ec5a2",
   "metadata": {},
   "source": [
    "| **Aspect**                      | **Manhattan Distance**                                   | **Euclidean Distance**                                   |\n",
    "|---------------------------------|--------------------------------------------------------|---------------------------------------------------------|\n",
    "| **Also Known As**               | L1 Distance, Taxicab Distance, City Block Distance     | L2 Distance, Straight-Line Distance                      |\n",
    "| **Geometry**                    | Represents the distance along grid lines (like a grid-based city) | Represents straight-line distance in Euclidean space     |\n",
    "| **Axes Independence**           | Treats each dimension independently (axis-aligned)     | Considers the interaction between dimensions            |\n",
    "| **Sensitivity to Outliers**     | More sensitive, as it considers only the absolute difference | Less sensitive, as it squares the differences            |\n",
    "| **Computation**                 | Requires the sum of absolute differences               | Requires the sum of squared differences, followed by a square root |\n",
    "| **Usage in Clustering**         | Often used in scenarios where movement is constrained to grid lines (e.g., logistics) | Commonly used when the data has a continuous and unconstrained distribution |\n",
    "| **Dimensionality**              | Works well in high-dimensional spaces                  | Works well but can be affected by the curse of dimensionality |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e107447",
   "metadata": {},
   "source": [
    "**Example**:\n",
    "\n",
    "Manhattan: $ |2-5| + |3-7| = 7 $    \n",
    "Euclidean: $ \\sqrt{(2-5)^2 + (3-7)^2} = \\sqrt{25} \\approx 5 $ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5361a34b",
   "metadata": {},
   "source": [
    "These differences highlight the characteristics of each distance metric, and the choice <br>\n",
    "between Manhattan Distance and Euclidean Distance often depends on the nature of the data and <br>\n",
    "the specific requirements of the clustering task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cdd412",
   "metadata": {},
   "source": [
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e940ed",
   "metadata": {},
   "source": [
    "## 5. What are some Stopping Criteria for k-Means Clustering?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21540d7",
   "metadata": {},
   "source": [
    "Stopping criteria for k-Means clustering are conditions that determine when the algorithm <br>\n",
    "should stop iterating and consider the clusters as sufficiently stable. <br>\n",
    "Here are some common stopping criteria for k-Means clustering:\n",
    "\n",
    "1. **Convergence:**\n",
    "   - Stop when the centroids no longer change significantly between iterations. <br>\n",
    "   This is often measured by the change in the sum of squared distances between data <br>\n",
    "   points and their assigned centroids.\n",
    "\n",
    "2. **Fixed Number of Iterations:**\n",
    "   - Set a predetermined maximum number of iterations. If the algorithm does not converge <br>\n",
    "   within this limit, stop and consider the current clusters as the result.\n",
    "\n",
    "3. **Inertia or Sum of Squared Distances:**\n",
    "   - Monitor the sum of squared distances (inertia) between data points and their assigned <br>\n",
    "   centroids. If the change in inertia between iterations falls below a threshold, <br>\n",
    "   consider the algorithm as converged.\n",
    "\n",
    "4. **Silhouette Score:**\n",
    "   - Use silhouette analysis to evaluate the quality of the clusters. Stop when the <br>\n",
    "   silhouette score reaches a satisfactory level. The silhouette score measures how <br>\n",
    "   well-separated clusters are and ranges from -1 to 1, with higher values indicating <br>\n",
    "   better-defined clusters.\n",
    "\n",
    "5. **Centroid Stability:**\n",
    "   - Check the stability of individual centroids. If the movement of centroids is below a <br>\n",
    "   certain threshold, the algorithm can be considered converged.\n",
    "\n",
    "6. **Percentage Change in Cluster Membership:**\n",
    "   - Monitor the percentage change in cluster membership between iterations. If the change <br>\n",
    "   falls below a specified threshold, the algorithm may have converged.\n",
    "\n",
    "7. **External Validation Metrics:**\n",
    "   - Use external metrics like external validation indices (e.g., Adjusted Rand Index, <br>\n",
    "   Fowlkes-Mallows Index) to assess the quality of clusters. Stop when these metrics <br>\n",
    "   reach a satisfactory level.\n",
    "\n",
    "8. **User-Specified Tolerance:**\n",
    "   - Allow users to define a tolerance level that determines when the algorithm is <br>\n",
    "   considered to have converged. This could be based on the percentage change in <br>\n",
    "   centroids or other relevant factors.\n",
    "\n",
    "Choosing the appropriate stopping criteria depends on the specific characteristics of the <br>\n",
    "data, the goals of the clustering task, and the desired trade-off between computational <br>\n",
    "efficiency and clustering quality. It's common to use a combination of these criteria for<br>\n",
    "a more comprehensive convergence assessment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4739add6",
   "metadata": {},
   "source": [
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e86c37",
   "metadata": {},
   "source": [
    "## 6. What is the main difference between k-Means <br> and k-Nearest Neighbours?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72a96be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "668724e9",
   "metadata": {},
   "source": [
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683f2a8f",
   "metadata": {},
   "source": [
    "## 7. How to decide the optimal number of K in  <br> the K means Algorithm?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef70e35b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "96a0f78f",
   "metadata": {},
   "source": [
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea88e30",
   "metadata": {},
   "source": [
    "## 8. What is WCSS?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c2b1f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2430fdf",
   "metadata": {},
   "source": [
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32ffe83",
   "metadata": {},
   "source": [
    "## 9. What is Elbow Method?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1615a2eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e3a451e5",
   "metadata": {},
   "source": [
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1b5b06",
   "metadata": {},
   "source": [
    "## 10. What is a centroid point in K means Clustering?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385ed98e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe740917",
   "metadata": {},
   "source": [
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee4ba66",
   "metadata": {},
   "source": [
    "## 11. Is Feature Scaling required for the <br> K means Algorithm?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c5b587",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "01beed8d",
   "metadata": {},
   "source": [
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ddeb26",
   "metadata": {},
   "source": [
    "## 12. What is Normalization? When to use it?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f01959",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b4eba3aa",
   "metadata": {},
   "source": [
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54d2da0",
   "metadata": {},
   "source": [
    "## 13. What is Standardization? When to use it?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5290698e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "771f37e1",
   "metadata": {},
   "source": [
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a676686",
   "metadata": {},
   "source": [
    "## 14. What will be the impact of outliers?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01f5895",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2bf3024",
   "metadata": {},
   "source": [
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974ddced",
   "metadata": {},
   "source": [
    "## 15. How would you Pre-Process the data for k-Means?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7835880f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1183c2f8",
   "metadata": {},
   "source": [
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa67e1de",
   "metadata": {},
   "source": [
    "## 16. Which metrics can you use to find the <br> accuracy of the K means Algorithm?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff72129",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5cee1fbd",
   "metadata": {},
   "source": [
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec17547e",
   "metadata": {},
   "source": [
    "## 17. What are the challenges associated with <br> K means Clustering?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71fdb49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82c44111",
   "metadata": {},
   "source": [
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1804c28",
   "metadata": {},
   "source": [
    "## 18. Explain some cases where K means <br> clustering fails to give good results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e5b2f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a8331bc3",
   "metadata": {},
   "source": [
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e9db0e",
   "metadata": {},
   "source": [
    "## 19. What are the advantages and disadvantages <br> of the K means Algorithm?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c2b9d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec078dce",
   "metadata": {},
   "source": [
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea952fe",
   "metadata": {},
   "source": [
    "## 20. What are the applications of the K-means algorithm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624c739f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d3ca966",
   "metadata": {},
   "source": [
    "-----------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
